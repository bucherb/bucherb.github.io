<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <!-- Hi, Jon Here. Please DELETE the two <script> tags below if you use this HTML, otherwise my analytics will track your page -->
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-7580334-2"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-7580334-2');
  </script>

  <title>Bernadette Bucher</title>

  <meta name="author" content="Bernadette Bucher">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Bernadette Bucher</name>
              </p>
              <p>
                I am a PhD Student in the <a href="https://www.grasp.upenn.edu/">GRASP lab</a> at <a href="https://home.www.upenn.edu/">University of Pennsylvania</a> advised by
                <a href="http://www.cis.upenn.edu/~kostas/">Dr. Kostas Daniilidis</a>.
</p><p>
                My research interests broadly lie in developing meaningful representations of sensory data in
                robotic systems for intelligent autonomous decision making. My current work
                focuses on neuromorphic approaches to perceptual decision making.
</p><p>
                Prior to starting my PhD, I was a Senior Software Engineer at <a href="https://www.lockheedmartin.com/en-us/index.html">Lockheed Martin Corporation</a>
                where I worked from 2014 to 2019. I received an M.A. in Mathematics, M.A. in Economics, and
                B.S. in Mathematics and Economics from <a href="https://www.ua.edu/">The University of Alabama</a> in 2014.
              </p>
              <p style="text-align:center">
                <a href="mailto:bucherb@seas.upenn.edu">Email</a> &nbsp/&nbsp
                <a href="data/BernadetteBucher.pdf">CV</a> &nbsp/&nbsp
                <a href="data/Bucher-bio.txt">Biography</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=VIZvaGsAAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/bernadette-bucher-09898536/"> LinkedIn </a>
              </p>
            </td>
            <td style="padding:2.5%;width:25%;max-width:25%">
              <a href="images/Bucher.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/Bucher.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/robonet.gif" alt="fast-texture" width="160" height="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/pdf/1910.11215.pdf">
                <papertitle>RoboNet: Large-Scale Multi-Robot Learning</papertitle>
              </a>
              <br>
              <a href="https://sudeepdasari.github.io/">Sudeep Dasari</a>, <a href="https://febert.github.io/">Frederik Ebert</a>, <a href="https://s-tian.github.io/">Stephen Tian</a>, <a href="https://cs.stanford.edu/~surajn/">Suraj Nair</a>, <strong>Bernadette Bucher</strong>, <a href="https://sites.google.com/view/karlschmeckpeper">Karl Schmeckpeper</a>, <a href="https://www.seas.upenn.edu/~sidsingh/">Siddharth Singh</a>, <a href="https://people.eecs.berkeley.edu/~svlevine/">Sergey Levine</a>, <a href="https://ai.stanford.edu/~cbfinn/">Chelsea Finn</a>
              <br>
              <em>Conference on Robot Learning (CoRL)</em>, 2019
              <br>
              <a href="https://arxiv.org/abs/1910.11215">arXiv</a> &nbsp/&nbsp <a href="https://www.robonet.wiki/">project page</a> &nbsp/&nbsp <a href="https://github.com/SudeepDasari/RoboNet">code</a> &nbsp/&nbsp <a href="data/CORL2019.bib">bibtex</a>
              <p>We developed a dataset of over 15 million video frames of 7 different robots at 113 different camera viewpoints interacting with objects. We use our new dataset to test the generalization capability of state-of-the-art video prediction algorithms.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/privateEye.png" alt="fast-texture" width="160" height="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://drive.google.com/file/d/1ec2d1URU4oVS4xM2QZzpYy5jQ67zpenX/view">
                <papertitle>Perception-Driven Curiosity with Bayesian Surprise</papertitle>
              </a>
              <br>
              <strong>Bernadette Bucher</strong>, Anton Arapin, Ramanan Sekar, Feifei Duan, <a href="https://www.ocf.berkeley.edu/~badger/">Marc Badger</a>, <a href="http://www.cis.upenn.edu/~kostas/">Kostas Daniilidis</a>, <a href="https://www.seas.upenn.edu/~oleh/">Oleh Rybkin</a>
              <br>
              <em>RSS Workshop on Combining Learning and Reasoning Towards Human-Level Robot Intelligence</em>, 2019
              <br>
              <a href="data/RSS2019.bib">bibtex</a>
              <p> We model scene dynamics with a conditional variational autoencoder from which we compute an intrinsic reward for curiosity for use in a reinforcement learning algorithm.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/monoDepth.png" alt="clean-usnob" width="160" height="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://scene-understanding.com/papers/UnsupervisedMonocularDepthAndLatentStructure.pdf.pdf">
                <papertitle>Unsupervised Monocular Depth And Latent Structure</papertitle>
              </a>
              <br>
              Kenneth Chaney*, <strong>Bernadette Bucher*</strong>, Evangelos Chatzipantazis, <a href="http://www.cis.upenn.edu/~jshi/">Jianbo Shi</a>, <a href="http://www.cis.upenn.edu/~kostas/">Kostas Daniilidis</a>
              <br>
              <em>CVPR Workshop on 3D Scene Understanding for Vision, Graphics, and Robotics</em>, 2019
              <br>
              <a href="data/CVPR2019.bib">bibtex</a>
              <p> We demonstrate a novel method for learning distinct latent representations of structural and semantic information from single monocular images which we use for novel viewpoint synthesis.
              </p>
            </td>
          </tr>

        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                <a href="https://jonbarron.info/">An inspirational website.</a>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
